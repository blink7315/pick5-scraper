name: Run pick5 scraper

on:
  workflow_dispatch: {}
  schedule:
    # === Tuesday late-night run (once, around 11â€“11:30 PM ET) === Take out the # from below during CFP ranking time
    # - cron: "30 3 * * 3"   # 03:30 UTC Wednesday = 10:30 PM ET (DST) / 11:30 PM ET (Standard) on Tuesday

    # === Tuesday evening runs (same local time as Thursday) === Only use this before CFP ranking time
    - cron: "0 21 * * 2"   # 5 PM ET during Daylight Time (21:00 UTC)
    - cron: "0 22 * * 2"   # 5 PM ET during Standard Time (22:00 UTC)

    # === Thursday evening runs (unchanged) ===
    - cron: "0 21 * * 4"   # 5 PM ET during Daylight Time (21:00 UTC)
    - cron: "0 22 * * 4"   # 5 PM ET during Standard Time (22:00 UTC)

concurrency:
  group: pick5-scraper
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Check out repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies (Python + Playwright)
        run: |
          python -m pip install --upgrade pip
          pip install playwright gspread google-auth gspread-formatting
          playwright install --with-deps chromium

      - name: Write Google service account file
        run: |
          cat > credentials.json <<'JSON'
          ${{ secrets.GOOGLE_SA_JSON }}
          JSON

      - name: Run scraper
        env:
          PICK_SHEET_ID: ${{ secrets.PICK_SHEET_ID }}
          COLLEGE_SHEET_ID: ${{ secrets.COLLEGE_SHEET_ID }}
          GOOGLE_SA_JSON: ${{ secrets.GOOGLE_SA_JSON }}
          PYTHONUNBUFFERED: "1"
          HEADLESS: "1"
          FORCE_WEEK_TABLE: "1"
          SKIP_PURGE: "0"
        run: python pick5_scraper.py
